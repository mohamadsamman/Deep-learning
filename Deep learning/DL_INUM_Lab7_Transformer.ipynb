{"cells":[{"cell_type":"markdown","metadata":{"id":"LFmaQ9uuYbDP"},"source":["# Lab 7: Transformer in Practice\n"]},{"cell_type":"markdown","metadata":{"id":"etCgF-aAiz_H"},"source":["In this lab, we train ``nn.TransformerEncoder`` model on a\n","language modeling task. The language modeling task is to assign a\n","probability for the likelihood of a given word (or a sequence of words) to follow a sequence of words.\n","\n","A sequence of tokens are passed to the embedding\n","layer first, followed by a positional encoding layer to account for the order\n","of the word (see the rest of the lab for more details). The\n","``nn.TransformerEncoder`` consists of multiple layers of\n","[``nn.TransformerEncoderLayer``](https://pytorch.org/docs/master/nn.html?highlight=transformerencoderlayer#torch.nn.TransformerEncoderLayer).\n","\n","Along with the input sequence, a square\n","attention mask is required because the self-attention layers in\n","``nn.TransformerEncoder`` are only allowed to attend the earlier positions in\n","the sequence. For the language modeling task, any tokens on the future\n","positions should be masked.\n","\n","To have the actual words, the output\n","of ``nn.TransformerEncoder`` model is sent to the final Linear\n","layer, which is followed by a log-Softmax function.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kusn3dblJa5s"},"source":["**This notebook was tested on Google colab with torch 2.0.0 and torchtext version 0.15.1**"]},{"cell_type":"markdown","metadata":{"id":"H4esKuC8YN5Z"},"source":["It could be necessary to install the appropriate versions of Torch and Torchtext on Google Colab (or your personal laptop)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oveLu8vjsjiL"},"outputs":[],"source":["!pip uninstall -y torch torchvision torchaudio torchtext\n","!pip install torch==2.0.0 torchvision torchaudio torchtext"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Iy2R23Wciz-_"},"outputs":[],"source":["%matplotlib inline\n","\n","import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","source":["print(torch.__version__)"],"metadata":{"id":"cavSjQFV6ixw"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"adlOFAk4tCfW"},"outputs":[],"source":["import torchtext\n","print(torchtext.__version__)"]},{"cell_type":"markdown","metadata":{"id":"uTEy4q9Oiz_H"},"source":["## Define the model\n","----------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Vo_0ukwLxAKD"},"source":["#### First steps with the transformer layers\n","\n","\"TransformerEncoderLayer\" is made up of self-attn and feedforward network. This standard encoder layer is based on the paper “Attention Is All You Need”.\n","\n","\"dim_feedforward\" is the dimension of the hidden layer in the feedforward neural network.\n","\n","More details on them [here](https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoderLayer.html#torch.nn.TransformerEncoderLayer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hEp6GFxBxAKE"},"outputs":[],"source":["encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8, dim_feedforward=1000)\n","src = torch.rand(10, 32, 512)\n","out = encoder_layer(src)\n","print(src.shape)\n","print(out.shape)"]},{"cell_type":"markdown","metadata":{"id":"wa75TCCDxAKE"},"source":["Create a transformer as a stack of encoder layers. \"TransformerEncoder\" is a stack of \"num_layers\" encoder layers.\n","\n","More details on them [here](https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html#torch.nn.TransformerEncoder)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zoy07AsVxAKE"},"outputs":[],"source":["encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n","transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n","src = torch.rand(9, 32, 512)\n","out = transformer_encoder(src)\n","print(src.shape)\n","print(out.shape)"]},{"cell_type":"markdown","metadata":{"id":"KfhE6s69xAKF"},"source":["### Question: what is the meaning of parameters in \"__init__\"?"]},{"cell_type":"markdown","metadata":{"id":"61HZaKslxAKF"},"source":["#### Response:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nj-Wo4KYxAKF"},"source":["### Question: explain how the \"forward\" function works? What is the role of the mask \"src_mask\"?"]},{"cell_type":"markdown","metadata":{"id":"iezcXc5ZxAKF"},"source":["#### Response:\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VvGmcEwgiz_I"},"outputs":[],"source":["class TransformerModel(nn.Module):\n","\n","    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n","        super(TransformerModel, self).__init__()\n","        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n","        self.model_type = 'Transformer'\n","        self.pos_encoder = PositionalEncoding(ninp, dropout)\n","        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n","        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n","        self.encoder = nn.Embedding(ntoken, ninp)\n","        self.ninp = ninp\n","        self.decoder = nn.Linear(ninp, ntoken)\n","\n","        self.init_weights()\n","\n","    # Generate an upper triangular mask: lower part is -inf and upper part is 0.0\n","    def generate_square_subsequent_mask(self, sz):\n","        # torch.triu returns a copy of a matrix with the elements below the k-th diagonal zeroed.\n","        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n","        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","        return mask\n","\n","    def init_weights(self):\n","        initrange = 0.1\n","        self.encoder.weight.data.uniform_(-initrange, initrange)\n","        self.decoder.bias.data.zero_()\n","        self.decoder.weight.data.uniform_(-initrange, initrange)\n","\n","    def forward(self, src, src_mask):\n","        src = self.encoder(src) * math.sqrt(self.ninp)\n","        src = self.pos_encoder(src) # add the positional encoding (pe) to src: src <- src + pe\n","        output = self.transformer_encoder(src, src_mask)\n","        output = self.decoder(output)\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"DwmST9ykiz_I"},"source":["### Positional Encoding\n","\n","``PositionalEncoding`` module injects some information about the\n","relative or absolute position of the tokens in the sequence. The\n","positional encodings have the same dimension as the embeddings so that\n","the two can be summed. Here, we use ``sine`` and ``cosine`` functions of\n","different frequencies.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2VQuWvdrxAKG"},"source":["### Question: what is the role of \"Positional Encoding\"."]},{"cell_type":"markdown","metadata":{"id":"d8Q2TQUTxAKG"},"source":["#### Response:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JjnutiJBiz_I"},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:x.size(0), :]\n","        return self.dropout(x)"]},{"cell_type":"markdown","metadata":{"id":"9eeitVxCxAKG"},"source":["### Question: What is the role of the mask \"src_mask\" in the class \"TransformerModel\"?"]},{"cell_type":"markdown","metadata":{"id":"MFr4GBVJxAKG"},"source":["#### Response:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pH5mfkj1iz_J"},"source":["Load and batch data\n","-------------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GTA_RjUGiz_J"},"source":["This tutorial uses ``torchtext`` to generate Wikitext-2 dataset. The\n","vocab object is built based on the train dataset and is used to numericalize\n","tokens into tensors. Starting from sequential data, the ``batchify()``\n","function arranges the dataset into columns, trimming off any tokens remaining\n","after the data has been divided into batches of size ``batch_size``.\n","For instance, with the alphabet as the sequence (total length of 26)\n","and a batch size of 4, we would divide the alphabet into 4 sequences of\n","length 6:\n","\n","\\begin{align}\\begin{bmatrix}\n","  \\text{A} & \\text{B} & \\text{C} & \\ldots & \\text{X} & \\text{Y} & \\text{Z}\n","  \\end{bmatrix}\n","  \\Rightarrow\n","  \\begin{bmatrix}\n","  \\begin{bmatrix}\\text{A} \\\\ \\text{B} \\\\ \\text{C} \\\\ \\text{D} \\\\ \\text{E} \\\\ \\text{F}\\end{bmatrix} &\n","  \\begin{bmatrix}\\text{G} \\\\ \\text{H} \\\\ \\text{I} \\\\ \\text{J} \\\\ \\text{K} \\\\ \\text{L}\\end{bmatrix} &\n","  \\begin{bmatrix}\\text{M} \\\\ \\text{N} \\\\ \\text{O} \\\\ \\text{P} \\\\ \\text{Q} \\\\ \\text{R}\\end{bmatrix} &\n","  \\begin{bmatrix}\\text{S} \\\\ \\text{T} \\\\ \\text{U} \\\\ \\text{V} \\\\ \\text{W} \\\\ \\text{X}\\end{bmatrix}\n","  \\end{bmatrix}\\end{align}\n","\n","These columns are treated as independent by the model, which means that\n","the dependence of ``G`` and ``F`` can not be learned, but allows more\n","efficient batch processing.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"w4_VHVXuxAKH"},"source":["#### What is TorchText?\n","\n","TorchText is a pytorch package that contains different data processing methods as well as popular NLP datasets. According to the official PyTorch documentation, torchtext has 4 main functionalities: data, datasets, vocab, and utils. Data is mainly used to create custom dataset class, batching samples etc. Datasets consists of the various NLP datasets from sentiment analysis to question answering. Vocab covers different methods of processing text and utils consists of additional helper functions."]},{"cell_type":"markdown","metadata":{"id":"e8ZrwYnrc6ec"},"source":["#### Warning: path to access the dataset\n","\n","The following variables \"from_path\" and \"to_path\" are necessary to store the dataset.\n","\n","They are defined for Google colab.\n","\n","You must change them if you are using your personal Python installation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GyaOM6k7c4sX"},"outputs":[],"source":["# Google Colab\n","from_path = '/content/sample_data/wikitext-2-v1.zip'\n","to_path = '/content/sample_data/'\n","\n","# Personal laptop\n","# from_path = './wikitext-2-v1.zip'\n","# to_path = './'"]},{"cell_type":"markdown","metadata":{"id":"kUd0qpUOdSCE"},"source":["Download and preprocess the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KDD3ZMPixyw9"},"outputs":[],"source":["import io\n","import torch\n","from torchtext.utils import download_from_url, extract_archive\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","\n","url = 'https://github.com/lionel-fillatre/DeepLearning/raw/refs/heads/main/wikitext-2-v1.zip'\n","download_from_url(url, from_path)\n","test_filepath, valid_filepath, train_filepath = extract_archive(from_path, to_path)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"SC08PBaQxAKH"},"source":["Print the file paths"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rSEZ3o1VkixN"},"outputs":[],"source":["print(test_filepath)\n","print(valid_filepath)\n","print(train_filepath)"]},{"cell_type":"markdown","metadata":{"id":"_K_cwaqPmC5T"},"source":["### Question: what is the role of \"tokenizer\".\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Lvx_OOCAxAKH"},"source":["#### Response:\n"]},{"cell_type":"markdown","metadata":{"id":"ngL5MUKixAKH"},"source":["### Question: what is the role of \"vocab\"?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uahME9BWxAKH"},"outputs":[],"source":["tokenizer = get_tokenizer('basic_english')\n","vocab = build_vocab_from_iterator(map(tokenizer,\n","                                      iter(io.open(train_filepath,\n","                                                   encoding=\"utf8\")))\n","                                  , specials=[\"<unk>\",\"<pad>\"])\n","vocab.set_default_index(vocab[\"<unk>\"])"]},{"cell_type":"markdown","metadata":{"id":"Q4PEofs2xAKI"},"source":["#### Response:\n"]},{"cell_type":"markdown","metadata":{"id":"2tm9x3jQxAKI"},"source":["### Question: what is the role of the function \"data_process\"?"]},{"cell_type":"markdown","metadata":{"id":"vvDKIQiZxAKI"},"source":["#### Response:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ANbVqGvKiz_J"},"outputs":[],"source":["def data_process(raw_text_iter):\n","  data = [torch.tensor([vocab[token] for token in tokenizer(item)],\n","                       dtype=torch.long) for item in raw_text_iter]\n","  return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n","\n","train_data = data_process(iter(io.open(train_filepath, encoding=\"utf8\")))\n","val_data = data_process(iter(io.open(valid_filepath, encoding=\"utf8\")))\n","test_data = data_process(iter(io.open(test_filepath, encoding=\"utf8\")))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CO-cCAw6xAKI"},"outputs":[],"source":["print(type(train_data))\n","# The length of train_data corresponds to the sequence of items that have been encoded.\n","print(train_data.shape)\n","# Print the 10 first first items as numbers\n","print(train_data[0:10])"]},{"cell_type":"markdown","metadata":{"id":"1xI4wgQDxAKI"},"source":["We reduce the size of the dataset to get results faster"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jsPQVbY2xAKI"},"outputs":[],"source":["print(train_data.shape)\n","print(val_data.shape)\n","print(test_data.shape)\n","train_data = train_data[0:10000]\n","val_data = val_data[0:10000]\n","test_data = test_data[0:10000]"]},{"cell_type":"markdown","metadata":{"id":"qtDYy5DikZPm"},"source":["Use a GPU if possible"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lbxzg8VMkOlV"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"Ym8sbZC3kWAm"},"source":["Create the batches"]},{"cell_type":"markdown","metadata":{"id":"zeXnOvHXxAKI"},"source":["### Question: what is the physical meaning (with respect to the raw text) of a batch?"]},{"cell_type":"markdown","metadata":{"id":"XChuGkkbxAKI"},"source":["#### Response:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pHhzTJ2FkQM-"},"outputs":[],"source":["def batchify(data, bsz):\n","    # Divide the dataset into bsz parts.\n","    nbatch = data.size(0) // bsz # number of elements in a batch\n","    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n","    data = data.narrow(0, 0, nbatch * bsz)\n","    # Evenly divide the data across the bsz batches.\n","    # \"contiguous()\" returns a contiguous in memory tensor containing the same data as self tensor.\n","    data = data.view(bsz, -1).t().contiguous()\n","    return data.to(device)\n","\n","batch_size = 20 # number of batches\n","eval_batch_size = 10\n","\n","import copy\n","train_data_initial = copy.deepcopy(train_data)\n","\n","train_data = batchify(train_data, batch_size)\n","val_data = batchify(val_data, eval_batch_size)\n","test_data = batchify(test_data, eval_batch_size)"]},{"cell_type":"markdown","metadata":{"id":"Z0NPamPsiz_K"},"source":["## Functions to generate input and target sequence\n","--------------------------------------------------"]},{"cell_type":"markdown","metadata":{"id":"5VHdaLV1iz_K"},"source":["``get_batch()`` function generates the input and target sequence for\n","the transformer model. It subdivides the source data into chunks of\n","length ``bptt``. For the language modeling task, the model needs the\n","following words as ``Target``. For example, with a ``bptt`` value of 2,\n","we’d get the following two Variables for ``i`` = 0:\n","\n","![](https://pytorch.org/tutorials/_images/transformer_input_target.png)\n","\n","It means that from each column of \"Input\" (a column is a sequence), we want to predict the column of \"Target\".\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"SqLw4A8DxAKJ"},"source":["### Question: what is returned by \"get_batch\"?"]},{"cell_type":"markdown","metadata":{"id":"APoSk6THxAKJ"},"source":["#### Response:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nV8xDmYLiz_K"},"outputs":[],"source":["bptt = 35\n","def get_batch(source, i):\n","    seq_len = min(bptt, len(source) - 1 - i)\n","    data = source[i:i+seq_len]\n","    target = source[i+1:i+1+seq_len].reshape(-1)\n","    return data, target"]},{"cell_type":"markdown","metadata":{"id":"zdtYDQLfiz_L"},"source":["Initiate an instance\n","--------------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Pknl3SUDiz_L"},"source":["The model is set up with the hyperparameter below. The vocab size is\n","equal to the length of the vocab object.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-OH8RSa6iz_L"},"outputs":[],"source":["ntokens = len(vocab.get_stoi()) # the size of vocabulary\n","emsize = 200 # embedding dimension (it corresponds to \"ninp\")\n","nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n","nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n","nhead = 2 # the number of heads in the multiheadattention models\n","dropout = 0.2 # the dropout value\n","model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)"]},{"cell_type":"markdown","metadata":{"id":"xIbuuW6niz_M"},"source":["Run the model\n","-------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ncoyLgh0iz_N"},"source":["[``CrossEntropyLoss``](https://pytorch.org/docs/master/nn.html?highlight=crossentropyloss#torch.nn.CrossEntropyLoss) is applied to track the loss and\n","[``SGD``](https://pytorch.org/docs/master/optim.html?highlight=sgd#torch.optim.SGD)\n","implements stochastic gradient descent method as the optimizer.\n","\n","The initial learning rate is set to 5.0. [``StepLR``](https://pytorch.org/docs/master/optim.html?highlight=steplr#torch.optim.lr_scheduler.StepLR) is\n","applied to adjust the learn rate through epochs.\n","\n","During the\n","training, we use\n","[``nn.utils.clip_grad_norm_``](https://pytorch.org/docs/master/nn.html?highlight=nn%20utils%20clip_grad_norm#torch.nn.utils.clip_grad_norm_)\n","function to scale all the gradient together to prevent exploding.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wn5wc3ukxAKJ"},"source":["### Question: what is the role of \"StepLR\"?"]},{"cell_type":"markdown","metadata":{"id":"1rgUxNpSxAKJ"},"source":["#### Response:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FOu7E0KOhx39"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","lr = 5.0 # learning rate\n","optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"]},{"cell_type":"markdown","metadata":{"id":"ZJgMXS-6xAKJ"},"source":["Perplexity is an evaluation criterion that has been well studied over the past few years\n","\n","Perplexity, called ppl in the next cell, is the exponentiation of the average cross entropy of a corpus (Mikolov et al., 2011)."]},{"cell_type":"markdown","metadata":{"id":"cbKMe6mGxAKJ"},"source":["### Question: what is the role of \"torch.nn.utils.clip_grad_norm_\"?"]},{"cell_type":"markdown","metadata":{"id":"ezEeniySxAKJ"},"source":["#### Response:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9e4uRgKjiz_N"},"outputs":[],"source":["import time\n","\n","log_interval = 20\n","\n","def train():\n","    model.train() # Turn on the train mode\n","    total_loss = 0.\n","    start_time = time.time()\n","    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n","    # Loop over the training batches\n","    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n","        data, targets = get_batch(train_data, i)\n","        optimizer.zero_grad()\n","        if data.size(0) != bptt:\n","            src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n","        output = model(data, src_mask)\n","        loss = criterion(output.view(-1, ntokens), targets)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","        # Print a summary each log_interval iterations\n","        # The summary is focused on the loss\n","        if batch % log_interval == 0 and batch > 0:\n","            cur_loss = total_loss / log_interval # compute the current loss over the log_interval\n","            elapsed = time.time() - start_time\n","            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n","                  'lr {:02.2f} | ms/batch {:5.2f} | '\n","                  'loss {:5.2f} | ppl {:8.2f}'.format(\n","                    epoch, batch, len(train_data) // bptt, scheduler.get_last_lr()[0],\n","                    elapsed * 1000 / log_interval,\n","                    cur_loss, math.exp(cur_loss)))\n","            total_loss = 0\n","            start_time = time.time()"]},{"cell_type":"markdown","metadata":{"id":"vdyFpoOUxAKK"},"source":["The next function evaluates a trained neural network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"byPVmsBBhs6S"},"outputs":[],"source":["def evaluate(eval_model, data_source):\n","    eval_model.eval() # Turn on the evaluation mode\n","    total_loss = 0.\n","    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n","    with torch.no_grad():\n","        for i in range(0, data_source.size(0) - 1, bptt):\n","            data, targets = get_batch(data_source, i)\n","            if data.size(0) != bptt:\n","                src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n","            output = eval_model(data, src_mask)\n","            output_flat = output.view(-1, ntokens)\n","            total_loss += len(data) * criterion(output_flat, targets).item()\n","    return total_loss / (len(data_source) - 1)"]},{"cell_type":"markdown","metadata":{"id":"G-xqhHcBiz_O"},"source":["Loop over epochs. Save the model if the validation loss is the best\n","we've seen so far. Adjust the learning rate after each epoch.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lDDZSKD_iz_O"},"outputs":[],"source":["best_val_loss = float(\"inf\")\n","epochs = 3 # The number of epochs\n","best_model = None\n","\n","for epoch in range(1, epochs + 1):\n","    epoch_start_time = time.time()\n","    train() # train a model for one epoch\n","    val_loss = evaluate(model, val_data) # evaluate the performance of the trained model\n","    # Print the performance of the trained model on the evaluation dataset\n","    print('-' * 89)\n","    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n","          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n","                                     val_loss, math.exp(val_loss)))\n","    print('-' * 89)\n","\n","    # Keep the model if the loss decreases\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        best_model = model\n","\n","    scheduler.step() # Update the scheduler step with \"StepLR\" at each epoch"]},{"cell_type":"markdown","metadata":{"id":"sX6eQys0iz_O"},"source":["Evaluate the model with the test dataset\n","-------------------------------------\n","\n","Apply the best model to check the result with the test dataset.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vvrXlHNfiz_O"},"outputs":[],"source":["test_loss = evaluate(best_model, test_data)\n","print('=' * 89)\n","print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n","    test_loss, math.exp(test_loss)))\n","print('=' * 89)"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":0}