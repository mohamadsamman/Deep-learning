{"cells":[{"cell_type":"markdown","metadata":{"id":"iogTCNRqJgcK"},"source":["# Lab 1: Torch basics\n","# The goal of this lab is to discover Pytorch, especially the Tensor concept.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hh6cps5cgC9g"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","import torch\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pe1KgPFqgC9m"},"outputs":[],"source":["torch.__version__"]},{"cell_type":"markdown","metadata":{"id":"lMn2UjdXgC9r"},"source":["Largely inspired from the tutorial [What is PyTorch?](https://pytorch.org/tutorials/beginner/former_torchies/tensor_tutorial.html)\n","\n","Tensors are used to encode the signal to process, but also the internal states and parameters of models.\n","\n","Manipulating data through this constrained structure allows to use CPUs and GPUs at peak performance.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"loUAlh7dyVpN"},"source":["## Tensors"]},{"cell_type":"markdown","metadata":{"id":"hlUFi857xt6Q"},"source":["Construct a 3x5 matrix, uninitialized:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2kLcNt8IgC9r"},"outputs":[],"source":["# Sets the default floating point dtype.\n","# This type will be used as default floating point type for type inference in torch.tensor().\n","torch.set_default_tensor_type('torch.FloatTensor')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RjUhHCJMgC9u"},"outputs":[],"source":["x = torch.empty(3,5)\n","print(x.type())\n","print(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MnRsrLh5gC9w"},"outputs":[],"source":["x = torch.randn(3,5)\n","print(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lfgpO7kUgC9z"},"outputs":[],"source":["print(x.size())"]},{"cell_type":"markdown","metadata":{"id":"NNLzvVKigC92"},"source":["torch.Size is in fact a [tuple](https://docs.python.org/3/tutorial/datastructures.html#tuples-and-sequences), so it supports the same operations."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W-o3sFH3gC92"},"outputs":[],"source":["x.size()[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LkQAasgtgC95"},"outputs":[],"source":["x.size() == (3,5)"]},{"cell_type":"markdown","metadata":{"id":"GDufwT0Kstxv"},"source":["Importance of the brackets when defining a tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wa9IPaaqsaPg"},"outputs":[],"source":["a = torch.tensor([2.0])\n","print(type(a))\n","print(a.dtype)\n","print(a.size())\n","\n","b = torch.tensor(2.0)\n","print(type(b))\n","print(b.dtype)\n","print(b.size())"]},{"cell_type":"markdown","metadata":{"id":"XeAg1TcMhyf4"},"source":["Select some columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DZaC-fXlgY6G"},"outputs":[],"source":["cols = torch.zeros(5, dtype=torch.bool)\n","print(cols)\n","cols[1] = True\n","cols[4] = True\n","print(cols)\n","c = x[:, cols]  # selects all rows, 2nd column and  5th column from x\n","print(c)"]},{"cell_type":"markdown","metadata":{"id":"t9v3syrRf-13"},"source":["All operations on the tensor that operate in-place on it will have an _ postfix."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zr3PP5oVf1SV"},"outputs":[],"source":["# x will be filled with the value 3.5\n","x.fill_(3.5)\n","print(x)"]},{"cell_type":"markdown","metadata":{"id":"SXPtlUXsgC96"},"source":["## Bridge to numpy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"61srdUzCgC97"},"outputs":[],"source":["y = x.numpy()\n","print(y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tFv5BzYsgC99"},"outputs":[],"source":["a = np.ones(5)\n","b = torch.from_numpy(a)\n","print(b)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lfpk2tfpgC9-"},"outputs":[],"source":["xr = torch.randn(3, 5)\n","a = np.ones(5).astype(int)\n","b = torch.from_numpy(a)\n","print(xr)\n","print(b)"]},{"cell_type":"markdown","metadata":{"id":"C6sKTTlZ0RmP"},"source":["### Question: print the type of the content (data) of variables a, b and xr"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k07dBWLRxARt"},"outputs":[],"source":["print(a.dtype) # Array or tensor data type\n","print(b.dtype)\n","print(xr.dtype)"]},{"cell_type":"markdown","metadata":{"id":"7fwWdAYjUuiN"},"source":["## Operations\n","\n","There are multiple syntaxes for operations. In the following\n","example, we will take a look at the addition operation.\n","\n","Addition: syntax 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4iASmmTAUxG0"},"outputs":[],"source":["x = torch.rand(5, 3)\n","y = torch.rand(5, 3)\n","print(x + y)"]},{"cell_type":"markdown","metadata":{"id":"H5NxjdPhVQP8"},"source":["Addition: syntax 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GwCo8DOcVRHq"},"outputs":[],"source":["print(torch.add(x, y))"]},{"cell_type":"markdown","metadata":{"id":"wNuL3H61VZvS"},"source":["Addition: providing an output tensor as argument"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hX1ffSunVail"},"outputs":[],"source":["result = torch.empty(5, 3)\n","torch.add(x, y, out=result)\n","print(result)"]},{"cell_type":"markdown","metadata":{"id":"-VK0_f0rVejB"},"source":["Addition: in-place"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rj0GKMgSVlGV"},"outputs":[],"source":["# adds x to y\n","y.add_(x)\n","print(y)"]},{"cell_type":"markdown","metadata":{"id":"EgNBadgeVscS"},"source":["**Note:** Any operation that mutates a tensor in-place is post-fixed with an ``_``.\n","    For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kOPtMoOkgC-G"},"source":["Any operation that mutates a tensor in-place is post-fixed with an ```_```\n","\n","For example: ```x.copy_(y)```, ```x.t_()```, will change ```x```."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hrOV0mQIgC-G"},"outputs":[],"source":["print(x.t())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LfNnD4vSgC-H"},"outputs":[],"source":["print(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5YdHeI8lgC-I"},"outputs":[],"source":["x.t_()\n","print(x)"]},{"cell_type":"markdown","metadata":{"id":"UfxHIL-mWyZl"},"source":["You can use standard NumPy-like indexing with all bells and whistles!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cz4M97B2Wtyu"},"outputs":[],"source":["print(x[:, 1])"]},{"cell_type":"markdown","metadata":{"id":"M6tsVH8zW8yB"},"source":["Resizing (very useful): If you want to resize/reshape tensor, you can use ``torch.view``:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k0qjaFPDW_3I"},"outputs":[],"source":["x = torch.randn(4, 4)\n","y = x.view(16)\n","z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n","print(x.size(), y.size(), z.size())"]},{"cell_type":"markdown","metadata":{"id":"fP8sTTCgXRak"},"source":["If you have a one element tensor, use ``.item()`` to get the value as a\n","Python number"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zaG9x6SHXSPw"},"outputs":[],"source":["x = torch.randn(1)\n","print(x)\n","print(x.item())"]},{"cell_type":"markdown","metadata":{"id":"mqCvPrp-XmZQ"},"source":["**Read later:**\n","\n","\n","  100+ Tensor operations, including transposing, indexing, slicing,\n","  mathematical operations, linear algebra, random numbers, etc.,\n","  are described\n","  [here](https://pytorch.org/docs/torch)."]},{"cell_type":"markdown","metadata":{"id":"8Jk-JGYpeCNz"},"source":["## 3D Tensors"]},{"cell_type":"markdown","metadata":{"id":"RTGbU2E-eLWF"},"source":["### Question: What is the size of the following tensor?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d-Dg4nyOeD4f"},"outputs":[],"source":["y = torch.tensor([\n","     [\n","       [1, 2, 3],\n","       [4, 5, 6]\n","     ],\n","     [\n","       [1, 2, 3],\n","       [4, 5, 6]\n","     ],\n","     [\n","       [1, 2, 3],\n","       [4, 5, 6]\n","     ]\n","   ])\n","print(y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2gBU82BTe0_y"},"outputs":[],"source":["print(y.shape)"]},{"cell_type":"markdown","metadata":{"id":"dOUGbVEUe9DC"},"source":["### Question: Explain the result of the next cell"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"14O04VMTe9eg"},"outputs":[],"source":["torch.sum(y, dim=0)"]},{"cell_type":"markdown","metadata":{"id":"Ev68h5j1ZUNH"},"source":["## Broadcasting semantics\n","\n","In short, if a PyTorch operation supports broadcast, then its Tensor arguments can be automatically expanded to be of equal sizes (without making copies of the data).\n","\n","Two tensors are “broadcastable” if the following rules hold:\n","\n","*   Each tensor has at least one dimension.\n","*   When iterating over the dimension sizes, **starting at the trailing dimension**, the dimension sizes must either be equal, one of them is 1, or one of them does not exist.\n","\n","If two tensors x, y are “broadcastable”, the resulting tensor size is calculated as follows:\n","* If the number of dimensions of x and y are not equal, prepend 1 to the dimensions of the tensor with fewer dimensions to make them equal length.\n","* Then, for each dimension size, the resulting dimension size is the max of the sizes of x and y along that dimension.\n","\n","More details [here](https://pytorch.org/docs/stable/notes/broadcasting.html)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P3f9hXLxZXQa"},"outputs":[],"source":["# can line up trailing dimensions to make reading easier\n","x=torch.empty(5,1,4,1)\n","y=torch.empty(  3,1,1)\n","print((x+y).size())\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LsYo7aBqaJ5F"},"outputs":[],"source":["# but not necessary:\n","x=torch.empty(1)\n","y=torch.empty(3,1,7)\n","print((x+y).size())\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0n_Y_hY6fxeL"},"source":["### Question: The following command does not work. Why?\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vq3SqanjaO6U"},"outputs":[],"source":["x=torch.empty(5,2,4,1)\n","y=torch.empty(  3,1,1)\n","#print((x+y).size())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ha4-WRJ0g4l9"},"outputs":[],"source":["x=2*torch.ones(  2,4)\n","y=torch.ones(3,2,4)\n","print(x+y)"]},{"cell_type":"markdown","metadata":{"id":"Afol8pk8VPUn"},"source":["### Question: What is the diffence between \"x = xr\" and \"x = xr.clone()\"?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ROIvJcOngC-E"},"outputs":[],"source":["x = xr.clone()\n","x.add_(-xr)\n","print(x)\n","print(xr)"]},{"cell_type":"markdown","metadata":{"id":"UWxZLzMrgC-J"},"source":["Also be careful, changing the torch tensor modify the numpy array and vice-versa..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lkcW43iugC-J"},"outputs":[],"source":["y=torch.ones(2,4)\n","print(y)\n","z = y.numpy()\n","print(z)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qvRrtvz1gC-K"},"outputs":[],"source":["np.add(z, 1, out=z)\n","print(\"z=\", z)\n","print(\"y=\", y,\"\\n\")\n","torch.add(y, -4, out=y)\n","print(\"z=\",z)\n","print(\"y=\",y)"]},{"cell_type":"markdown","metadata":{"id":"AmGizC3pMbm8"},"source":["## Computational graphs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O5Kw7MQpMxWB"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Gza10WeM10G"},"outputs":[],"source":["# Install torchviz if not installed before on your laptop\n","!pip install torchviz\n","\n","# WARNING: You should install the graphviz package in your system (not just the python package).\n","# If so, you must visit\n","# https://graphviz.org/download/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1nEbmC7TM1mw"},"outputs":[],"source":["import torchviz"]},{"cell_type":"markdown","metadata":{"id":"Sl_8ex--LGGy"},"source":["### Question: Give an interpretation of the information in the graph drawn in the next cell."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Z2dMtEOMuWb"},"outputs":[],"source":["x = torch.ones(2, 2, requires_grad=True)\n","w = torch.rand(1, 1, requires_grad=True)\n","print(x)\n","print(w)\n","y = w * x + 2\n","print(y)\n","torchviz.make_dot(y)"]},{"cell_type":"markdown","metadata":{"id":"AsKmpu9WJgdy"},"source":["## Create your first neural network (with random parameters)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XZ3YcUCaJgdy"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"markdown","metadata":{"id":"psfNXuxMJgd0"},"source":["Let's define the neural network model as a class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YkwqeCOEJgd0"},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self):\n","      super(Net, self).__init__()\n","      self.fc1 = nn.Linear(20, 10)\n","      self.fc2 = nn.Linear(10, 4)\n","\n","    # x represents our input data\n","    def forward(self, x):\n","      # Pass data through fc1\n","      x = self.fc1(x)\n","      x = F.relu(x)\n","      x = self.fc2(x)\n","\n","      # Apply softmax to x\n","      output = F.softmax(x, dim=1)\n","      return output"]},{"cell_type":"markdown","metadata":{"id":"63yr0-OnJgd2"},"source":["Let’s instantiate the neural network model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4EHGce4iJgd3"},"outputs":[],"source":["my_nn = Net()"]},{"cell_type":"markdown","metadata":{"id":"y2GD_KIBUTgS"},"source":["### Question: test the model by passing some random data through it (3 random vectors following a normal distribution)\n","\n","Hint: you can look at https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zADMlk1oJgd5"},"outputs":[],"source":["# Test with 3 random vectors\n","random_data = torch.randn((3, 20))\n","result = my_nn(random_data)\n","print(result)"]},{"cell_type":"markdown","metadata":{"id":"GyHdjfniJ0QO"},"source":["### Question: print the computational graph of the neural network with the names of the parameters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UWc3OhaqJtn7"},"outputs":[],"source":["torchviz.make_dot(result, params=dict(my_nn.named_parameters()))"]},{"cell_type":"markdown","metadata":{"id":"zoFY0CMvJgd7"},"source":["### Question: Verify the sum of each output. How to interpret the output?"]},{"cell_type":"markdown","metadata":{"id":"qeTY-oiSJgd7"},"source":["The output can be interpreted as a discrete probability distribution between 3 classes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oSfMUonxJgd8"},"outputs":[],"source":["print(torch.sum(result,1))"]}],"metadata":{"colab":{"provenance":[{"file_id":"1dWLt0NwaFfqeIFDcqUvAbvtUZX0WsfaA","timestamp":1584569161578},{"file_id":"1FSHBnWienaS-J9cZvZqFvgKqKvFE8TzL","timestamp":1570973830446},{"file_id":"1KOuMuh8RKiWRk9jswod-tvc9lGFTJS2T","timestamp":1570913885656}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":0}