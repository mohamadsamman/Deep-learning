{"cells":[{"cell_type":"markdown","id":"180f686d-0642-4028-a9a5-e2f9fe8b7858","metadata":{"id":"180f686d-0642-4028-a9a5-e2f9fe8b7858"},"source":["# Visualize the kernel weights of the first convolution layer"]},{"cell_type":"code","execution_count":null,"id":"a9e8cc52-2753-405d-95b1-0c31c8e1183a","metadata":{"id":"a9e8cc52-2753-405d-95b1-0c31c8e1183a"},"outputs":[],"source":["# Load alexnet pretrained model\n","import torchvision.models as models\n","model = models.alexnet(weights='AlexNet_Weights.DEFAULT')"]},{"cell_type":"code","execution_count":null,"id":"6378e6e4-15ae-4a32-9c44-39daa1084dd8","metadata":{"id":"6378e6e4-15ae-4a32-9c44-39daa1084dd8"},"outputs":[],"source":["# Print the modules that compose the neural network\n","#model.modules()\n","for module in model.modules():\n","  print(module)"]},{"cell_type":"code","execution_count":null,"id":"0a62daa1-650e-4baf-b563-bb65016041ec","metadata":{"id":"0a62daa1-650e-4baf-b563-bb65016041ec"},"outputs":[],"source":["# Print the first module with convolutions\n","model.features"]},{"cell_type":"code","execution_count":null,"id":"10e1e058-d643-4057-a303-f847da20bdf3","metadata":{"id":"10e1e058-d643-4057-a303-f847da20bdf3"},"outputs":[],"source":["# Print the second module with classification\n","model.classifier"]},{"cell_type":"markdown","id":"1810aa77-1851-4161-bfed-b10be71601b3","metadata":{"id":"1810aa77-1851-4161-bfed-b10be71601b3"},"source":["## How to visualize the first layer filters?"]},{"cell_type":"code","execution_count":null,"id":"54b8a46e-efcd-4d3e-9d3f-26215b41ddfc","metadata":{"id":"54b8a46e-efcd-4d3e-9d3f-26215b41ddfc"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from torchvision import utils\n","\n","def visTensor(tensor, nrow=8, padding=1):\n","    n,c,w,h = tensor.shape\n","\n","    # Make a grid of images: the first dimension of the input tensor is the total number of images\n","    # The other dimensions of the tensor are the dimensions of a single image\n","    rows = np.min((tensor.shape[0] // nrow + 1, 64)) # number of rows\n","    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n","    plt.figure( figsize=(nrow,rows) )\n","    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n","\n","# Print the filter weights of Alexnet\n","layer = 0 # for alexnet, this is the first convolutional layer\n","filter = model.features[layer].weight.data.clone()\n","visTensor(filter)\n","\n","plt.axis('off')\n","plt.ioff()\n","plt.show()"]},{"cell_type":"markdown","id":"7fe9d63b-57f7-43bb-a9f6-b64eb02643f5","metadata":{"id":"7fe9d63b-57f7-43bb-a9f6-b64eb02643f5"},"source":["# 1D Convolution in Pytorch"]},{"cell_type":"code","execution_count":null,"id":"0f00fa08-0735-42be-b55b-9aea9a438116","metadata":{"id":"0f00fa08-0735-42be-b55b-9aea9a438116"},"outputs":[],"source":["import torch\n","out_channel_number = 4 # number of out channels\n","in_channel_number = 2 # number of in channels\n","w = 3 # 1D filter length\n","W = 5 # 1D input signal length\n","batch_size = 3\n","filters = torch.randn(out_channel_number, in_channel_number, w)\n","inputs = torch.randn(batch_size, in_channel_number, W)\n","bias = torch.empty(out_channel_number).normal_()\n","outputs = torch.nn.functional.conv1d(inputs, filters,bias)\n","print(inputs)\n","print(outputs)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}